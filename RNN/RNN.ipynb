{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Recurrent Neural Network to predict Google's stock price**  \n",
    "\n",
    "Predict Google's stock price in January 2017 based on the stock prices of 2012 to 2016. Visualise the results and check if they are similar to the results in actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 - Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Shrivatav\\\\Desktop\\\\Deep Learning A-Z\\\\Deep_Learning_A_Z\\\\Volume 1 - Supervised Deep Learning\\\\Part 3 - Recurrent Neural Networks (RNN)\\\\Section 12 - Building a RNN\\\\Recurrent_Neural_Networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "data_train = pd.read_csv(\"Google_Stock_Price_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subset to select input data for RNN\n",
    "# Select only 'Open' column and convert to array since RNNs take arrays as inputs\n",
    "training_set = data_train.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature scaling - scale values to [0,1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "training_set_scaled = scaler.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with 60 timesteps and 1 output\n",
    "# 60 day timestep - LSTM looks at previous 60 days data to decide next output for 1 day\n",
    "# Example, for 1st iteration, it'll use values from index 0 to 59 to learn output for index 60\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "    \n",
    "# Convert to numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368, 0.09701243, 0.09433366, ..., 0.07846566, 0.08034452,\n",
       "        0.08497656],\n",
       "       [0.09701243, 0.09433366, 0.09156187, ..., 0.08034452, 0.08497656,\n",
       "        0.08627874],\n",
       "       [0.09433366, 0.09156187, 0.07984225, ..., 0.08497656, 0.08627874,\n",
       "        0.08471612],\n",
       "       ...,\n",
       "       [0.92106928, 0.92438053, 0.93048218, ..., 0.95475854, 0.95204256,\n",
       "        0.95163331],\n",
       "       [0.92438053, 0.93048218, 0.9299055 , ..., 0.95204256, 0.95163331,\n",
       "        0.95725128],\n",
       "       [0.93048218, 0.9299055 , 0.93113327, ..., 0.95163331, 0.95725128,\n",
       "        0.93796041]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First row of X_train contains stock prices from day 0 to day 59\n",
    "# Second row of X_train contains stock prices from day 1 to day 60 .... and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First row of y_train contains stock price of day 60\n",
    "# Second row of y_train contains stock price of day 61 .... and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "# Reshape according to layer formatting for Recurrent Networks according\n",
    "# to Keras documentation\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1198, 60, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axis = 0 indicates the number of samples we have. The 1198 rows.  \n",
    "Axis = 1 indicates the number of timesteps in each row/sample. Length of axis = 1 would be 60.  \n",
    "Axis = 2 indicates the number of features in each timestep. In this example, we use 1 feature per timestep (the 'Open' price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - Building the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shrivatav\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inititalise the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add first LSTM layer and Dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add second LSTM layer and Dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add third LSTM layer and Dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add fourth LSTM layer and Dropout regularization\n",
    "regressor.add(LSTM(units = 50)) # return_sequences = False since it is the last hidden layer\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "# Fully connected layer with one output neuron\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the RNN\n",
    "# Can use RMSProp as optimizer as well\n",
    "regressor.compile(optimizer = \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 13s 11ms/step - loss: 0.0716\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0069\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0050\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 5s 5ms/step - loss: 0.0060\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0043\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0043\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0043\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0042\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0042\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0047\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0041\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0043\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0043\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0041\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0034\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0033\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0034\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0033\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0035\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0038\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0034\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0032\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0033\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0030\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0029\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0030\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0030\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0034\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0032\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0026\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0028\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0027\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0027\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0024\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0028\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0028\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0021\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0027\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0024\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0021\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0020\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0020\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0021\n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0014\n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 95/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0014\n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cb137ac18>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit RNN to training data\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 - Making predictions and visualizing results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data - Real stock prices for January 2017\n",
    "data_test = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
    "real_stock_prices = data_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[778.81],\n",
       "       [788.36],\n",
       "       [786.08],\n",
       "       [795.26],\n",
       "       [806.4 ],\n",
       "       [807.86],\n",
       "       [805.  ],\n",
       "       [807.14],\n",
       "       [807.48],\n",
       "       [807.08],\n",
       "       [805.81],\n",
       "       [805.12],\n",
       "       [806.91],\n",
       "       [807.25],\n",
       "       [822.3 ],\n",
       "       [829.62],\n",
       "       [837.81],\n",
       "       [834.71],\n",
       "       [814.66],\n",
       "       [796.86]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stock prices for January 2017\n",
    "# Our model is trained to predict stock price of day t+1 based on previous 60 days stock prices\n",
    "# Concatenate data_train and data_test so that we get data for days of January\n",
    "\n",
    "# Concatenation done vertically on \"Open\" column\n",
    "data_merged = pd.concat((data_train[\"Open\"], data_test[\"Open\"]), axis = 0)\n",
    "# Required range - from 60 days before 3rd January to last record in data_total \n",
    "inputs = data_merged[len(data_merged) - len(data_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1) # Reshape to avoid NumPy error/warning\n",
    "inputs = scaler.transform(inputs) # Use transform() instead of fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data with 60 timesteps and 1 output\n",
    "# 60 day timestep - LSTM looks at previous 60 days data to decide next output for 1 day\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "    \n",
    "# Convert to numpy arrays\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_stock_prices = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse scaling\n",
    "predicted_stock_prices = scaler.inverse_transform(predicted_stock_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[777.9669 ],\n",
       "       [774.903  ],\n",
       "       [776.1021 ],\n",
       "       [778.3017 ],\n",
       "       [782.40045],\n",
       "       [789.2216 ],\n",
       "       [794.6717 ],\n",
       "       [795.7533 ],\n",
       "       [795.1333 ],\n",
       "       [794.6549 ],\n",
       "       [794.6516 ],\n",
       "       [794.67053],\n",
       "       [794.66626],\n",
       "       [795.46204],\n",
       "       [796.60034],\n",
       "       [802.3958 ],\n",
       "       [810.4645 ],\n",
       "       [818.2787 ],\n",
       "       [821.15894],\n",
       "       [813.85706]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28cb4368668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visuale the results\n",
    "%matplotlib inline\n",
    "plt.plot(real_stock_prices, color = \"red\", label = \"Real Stock Price\")\n",
    "plt.plot(predicted_stock_prices, color = \"blue\", label = \"Predicted Stock Price\")\n",
    "plt.title(\"Google Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that out model follows the smooth curves well, but does not do well when there are spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways of improving the model:\n",
    "- More training data\n",
    "- More number of timesteps (>60)\n",
    "- More LSTM layers\n",
    "- More units in each LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
